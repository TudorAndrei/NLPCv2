Language Processing Homework
Natural Language Processing Homework nr. 1
# Task 1. Reading the .txt file.
        Download the folder with data from here: https://drive.google.com/drive/folders/1QiTxxzmNGqqxsEmyVwdXa-1lTbVmtHZj?usp=sharing
        Open with the python open function the file “class_11_biology_chapter_1_0.txt” from the “TEST/biology” folder. Extract the full content of the file in one unique string at the lower case.
NOTE: The following tasks should be done on the string in the lower case.


# Task 2. Obtain the file metadata.
        Get the following metadata about the content of the file.
1. The number of sentences extracted by sent_tokenize from nltk.
2. The number of unique tokens obtained with word_tokenize from nltk.
3. The number of unique tokens obtained with casual_tokenize from nltk.
4. The number of unique tokens obtained with MWETokenizer from nltk.
5. The mean number of words (tokens) per sentence in the text by every tokenizer.
HINT: Save the unique tokens obtained by every tokenizer in a set you will need it for the next task.


# Task 3. Comparing the Stemmers.
        Get the union of all unique tokens found by every tokenizer. Use this new created set to find the stemmed form of this token generated by every of the following stemmers - PorterStemmer, LancasterStemmer and SnowballStemmer. Save the result in a pandas DataFrame of the following form.


original_token
	porter
	Lancaster
	Snowball
	token
	token
	token
	token
	        Compare the result and differences of every stemmer.


# Task 4. Frequencies of words.
        Using the lower case string obtained from the file, get the frequencies of the word. What are the 10 most frequent tokens?
        Extract the list of the hapaxes.
        Plot the frequency of the words in the descending order as a scatter plot, How similar it is to the zipf law? Why?
# Task 5. Part of speech tagging.
        Extract from the text the part of speech of every token, and group them in dictionary with the following form:

        {“POS” : [list of tokens with this POS] }
        What is the most common part of speech and why? What is the part of speech that has the smallest frequency?
